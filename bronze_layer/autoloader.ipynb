{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "35b0f1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6df5f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.5.0']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using %system\n",
    "%system python -c \"import pyspark; print(pyspark.__version__)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7f377c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"BronzeAutoloader\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.jars\", r\"C:\\path\\to\\delta-spark-3.1.0.jar\")  # downloaded manually\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f22908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = ['customers','orders','products','deliveries']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e0ab5e",
   "metadata": {},
   "source": [
    "Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a63bd311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schemas in DDL format\n",
    "my_schemas = {\n",
    "    \"customers\": \"\"\"\n",
    "        customer_id STRING,\n",
    "        name STRING,\n",
    "        email STRING,\n",
    "        phone STRING,\n",
    "        address STRING,\n",
    "        last_updated TIMESTAMP\n",
    "    \"\"\",\n",
    "    \"products\": \"\"\"\n",
    "        product_id STRING,\n",
    "        product_name STRING,\n",
    "        category STRING,\n",
    "        price DOUBLE,\n",
    "        stock_quantity INT,\n",
    "        last_updated TIMESTAMP\n",
    "    \"\"\",\n",
    "    \"orders\": \"\"\"\n",
    "        order_id STRING,\n",
    "        customer_id STRING,\n",
    "        product_id STRING,\n",
    "        quantity INT,\n",
    "        total_amount DOUBLE,\n",
    "        order_date TIMESTAMP,\n",
    "        last_updated TIMESTAMP\n",
    "    \"\"\",\n",
    "    \"deliveries\": \"\"\"\n",
    "        delivery_id STRING,\n",
    "        order_id STRING,\n",
    "        delivery_date TIMESTAMP,\n",
    "        status STRING,\n",
    "        delivery_partner STRING,\n",
    "        last_updated TIMESTAMP\n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e24f1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = r\"C:\\Users\\User\\Desktop\\E-Commerce Data Lakaehouse with AI-Powered Self-Healing Pipelines\"\n",
    "\n",
    "for src, my_schema in my_schemas.items():\n",
    "    raw_path = f\"{base_path}\\\\raw_data\\\\{src}\"\n",
    "    bronze_data_path = f\"{base_path}\\\\bronze_layer\\\\{src}\\\\data\"\n",
    "    checkpoint_path = f\"{base_path}\\\\bronze_layer\\\\{src}\\\\checkpoint\"\n",
    "\n",
    "    # Read with schema\n",
    "    data = spark.readStream.format(\"csv\")\\\n",
    "                            .option(\"header\",\"true\")\\\n",
    "                            .schema(my_schema)\\\n",
    "                            .load(raw_path)\\\n",
    "                            .withColumn(\"ingestion_timestamp\",current_timestamp())\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79afba47",
   "metadata": {},
   "source": [
    "Write to Bronze data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf8f6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.writeStream.format(\"delta\")\\\n",
    "                .option(\"checkpointLocation\",checkpoint_path)\\\n",
    "                .option(\"path\",bronze_data_path)\\\n",
    "                .trigger(once=True)\\\n",
    "                .start()\n",
    "\n",
    "spark.stream.awaitAnyTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
